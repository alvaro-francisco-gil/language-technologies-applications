{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question-Answer Validation: Large Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/alvaro-francisco-gil/language-technologies-applications/blob/main/exercises/02_classification_by_llm.ipynb) \n",
        "[![View on GitHub](https://img.shields.io/badge/Open%20on-GitHub-blue?logo=github)](https://github.com/alvaro-francisco-gil/language-technologies-applications/blob/main/exercises/02_classification_by_llm.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The task of this experiment is to measure how much of the truthfulness of a question-answer pair can be inferred using both machine learning and deep learning approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running this notebook in Google Colab, you can install the required packages by running the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install torch pandas numpy seaborn matplotlib #and the rest of the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ld2bWB62Wm",
        "outputId": "b55083a9-4d72-4d37-d172-835a30e2b6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "import glob\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available splits: dict_keys(['train', 'validation'])\n",
            "Training set size: (9427, 3)\n",
            "Validation set size: (3270, 3)\n",
            "\n",
            "Example data point:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'do iran and afghanistan speak the same language',\n",
              " 'answer': True,\n",
              " 'passage': 'Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boolq = load_dataset(\"boolq\")\n",
        "\n",
        "print(f\"Available splits: {boolq.keys()}\")\n",
        "print(f\"Training set size: {boolq['train'].shape}\")\n",
        "print(f\"Validation set size: {boolq['validation'].shape}\")\n",
        "\n",
        "print(\"\\nExample data point:\")\n",
        "boolq[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this task, we chose the dataset boolq, which is a dataset of boolean questions and answers. As our aim is not directly answering the question, but evaluating wether the answer of a question is correct, we first need to transform the dataset into a question-answer format. For this, we divide each datapoint into two, the correct question-answer pair and the incorrect one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training examples:\n",
            "{'text': \"The question is 'do iran and afghanistan speak the same language' and the answer is 'True'\", 'label': 'correct'}\n",
            "{'text': \"The question is 'do iran and afghanistan speak the same language' and the answer is 'False'\", 'label': 'incorrect'}\n",
            "\n",
            "Validation examples:\n",
            "{'text': \"The question is 'does ethanol take more energy make that produces' and the answer is 'False'\", 'label': 'correct'}\n",
            "{'text': \"The question is 'does ethanol take more energy make that produces' and the answer is 'True'\", 'label': 'incorrect'}\n"
          ]
        }
      ],
      "source": [
        "# Create new training and validation datasets with correct and incorrect question-answer pairs\n",
        "new_train_data = []\n",
        "new_validation_data = []\n",
        "\n",
        "# Process training data\n",
        "for example in boolq[\"train\"]:\n",
        "    # Create correct pair\n",
        "    correct_pair = {\n",
        "        \"text\": f\"The question is '{example['question']}' and the answer is '{example['answer']}'\",\n",
        "        \"label\": \"correct\"\n",
        "    }\n",
        "    new_train_data.append(correct_pair)\n",
        "    \n",
        "    # Create incorrect pair\n",
        "    incorrect_pair = {\n",
        "        \"text\": f\"The question is '{example['question']}' and the answer is '{not example['answer']}'\",\n",
        "        \"label\": \"incorrect\"\n",
        "    }\n",
        "    new_train_data.append(incorrect_pair)\n",
        "\n",
        "# Process validation data\n",
        "for example in boolq[\"validation\"]:\n",
        "    # Create correct pair\n",
        "    correct_pair = {\n",
        "        \"text\": f\"The question is '{example['question']}' and the answer is '{example['answer']}'\",\n",
        "        \"label\": \"correct\"\n",
        "    }\n",
        "    new_validation_data.append(correct_pair)\n",
        "    \n",
        "    # Create incorrect pair\n",
        "    incorrect_pair = {\n",
        "        \"text\": f\"The question is '{example['question']}' and the answer is '{not example['answer']}'\",\n",
        "        \"label\": \"incorrect\"\n",
        "    }\n",
        "    new_validation_data.append(incorrect_pair)\n",
        "\n",
        "print(\"Training examples:\")\n",
        "print(new_train_data[0])\n",
        "print(new_train_data[1])\n",
        "print(\"\\nValidation examples:\")\n",
        "print(new_validation_data[0])\n",
        "print(new_validation_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6540"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(new_validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By composition, the dataset will be perfectly balanced, with 50% of the data being correct and 50% being incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separate x and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The question is 'do iran and afghanistan speak the same language' and the answer is 'True'\n",
            "correct\n"
          ]
        }
      ],
      "source": [
        "X_train = [example['text'] for example in new_train_data]\n",
        "y_train = [example['label'] for example in new_train_data]\n",
        "\n",
        "X_validation = [example['text'] for example in new_validation_data]\n",
        "y_validation = [example['label'] for example in new_validation_data]\n",
        "\n",
        "print(X_train[0])\n",
        "print(y_train[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Answer Capabilities Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a benchmark, we first evaluate the performance of an LLM in answering questions directly, which allows us to measure the performance gap between different question framings. While the main goal of this study is to evaluate the truthfulness of question-answer pairs, we begin by assessing the model's ability to answer questions directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_boolq_llm(\n",
        "    test_data, \n",
        "    model_name=\"gpt-4\", \n",
        "    use_passage=False, \n",
        "    results_dir=\"results\", \n",
        "    timeout=60.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate BoolQ by asking the LLM to answer the question, optionally with passage as context.\n",
        "    Args:\n",
        "        test_data: List of dicts with 'question', 'answer', and 'passage'\n",
        "        model_name: LLM model name\n",
        "        use_passage: If True, include passage in the prompt\n",
        "        results_dir: Where to save results\n",
        "        timeout: API timeout\n",
        "    \"\"\"\n",
        "    client = OpenAI(timeout=timeout)\n",
        "    Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
        "    results = {\n",
        "        \"model\": model_name,\n",
        "        \"task\": \"answering-boolq\",\n",
        "        \"use_passage\": use_passage,\n",
        "        \"total_examples\": len(test_data),\n",
        "        \"predictions\": [],\n",
        "        \"metadata\": {\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"timeout\": timeout\n",
        "        }\n",
        "    }\n",
        "    for i, ex in enumerate(test_data):\n",
        "        if use_passage:\n",
        "            prompt = (\n",
        "                \"You are given a passage and a question. Answer the question with 'True' or 'False'.\\n\\n\"\n",
        "                f\"Passage: {ex['passage']}\\n\"\n",
        "                f\"Question: {ex['question']}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "        else:\n",
        "            prompt = (\n",
        "                \"You are given a question. Answer with 'True' or 'False'.\\n\\n\"\n",
        "                f\"Question: {ex['question']}\\n\"\n",
        "                \"Answer:\"\n",
        "            )\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "            answer = response.choices[0].message.content.strip()\n",
        "            results[\"predictions\"].append({\n",
        "                \"example_id\": i,\n",
        "                \"question\": ex[\"question\"],\n",
        "                \"passage\": ex[\"passage\"] if use_passage else None,\n",
        "                \"ground_truth\": ex[\"answer\"],\n",
        "                \"prediction\": answer\n",
        "            })\n",
        "            # Save every 10 examples\n",
        "            if (i + 1) % 10 == 0:\n",
        "                with open(f\"{results_dir}/boolq_eval_{model_name}_{'withpassage' if use_passage else 'nopassage'}.json\", \"w\") as f:\n",
        "                    json.dump(results, f, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error on example {i}: {e}\")\n",
        "            results[\"predictions\"].append({\n",
        "                \"example_id\": i,\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "    # Save final results\n",
        "    with open(f\"{results_dir}/boolq_eval_{model_name}_{'withpassage' if use_passage else 'nopassage'}.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3270"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = [dict(q) for q in boolq[\"validation\"]]\n",
        "len(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset is composed also by the passage, which is a text that can be used to answer the question. We try both with and without passage to measure the difference in performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# With passage\n",
        "results_with_passage = evaluate_boolq_llm(\n",
        "    test_data=test_data,\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    use_passage=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Without passage\n",
        "results_no_passage = evaluate_boolq_llm(\n",
        "    test_data=test_data,\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    use_passage=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grading Capabilities Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we move to the main goal of the experiment, which is to evaluate the truthfulness of a question-answer pair. We do this by asking the LLM to grade the question-answer pair as correct or incorrect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_qa_pair_judgment_llm(\n",
        "    test_data: List[Dict[str, Any]],\n",
        "    model_name: str = \"gpt-4o-mini\",\n",
        "    use_context: bool = False,  # Not used, but kept for compatibility\n",
        "    results_dir: str = \"results\",\n",
        "    timeout: float = 900.0\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Evaluate LLM's ability to judge if a question-answer pair is correct.\n",
        "    Args:\n",
        "        test_data: List of dicts with 'text' (e.g., \"The question is ... and the answer is ...\") and 'label' (\"correct\"/\"incorrect\")\n",
        "        model_name: LLM model name\n",
        "        use_context: (ignored, for compatibility)\n",
        "        results_dir: Where to save results\n",
        "        timeout: API timeout\n",
        "    \"\"\"\n",
        "    client = OpenAI(timeout=timeout)\n",
        "    Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
        "    results = {\n",
        "        \"model\": model_name,\n",
        "        \"task\": \"grading-boolq\",\n",
        "        \"use_context\": use_context,\n",
        "        \"total_examples\": len(test_data),\n",
        "        \"predictions\": [],\n",
        "        \"metadata\": {\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"timeout\": timeout\n",
        "        }\n",
        "    }\n",
        "    for i, ex in enumerate(test_data):\n",
        "        prompt = (\n",
        "            \"You are given a question and an answer. \"\n",
        "            \"Evaluate if the answer is correct for the question. \"\n",
        "            \"Respond with {\\\"answer\\\": \\\"correct\\\"} or {\\\"answer\\\": \\\"incorrect\\\"}.\\n\\n\"\n",
        "            f\"{ex['text']}\\n\"\n",
        "        )\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that evaluates if answers to questions are correct.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "            prediction = response.choices[0].message.content.strip()\n",
        "            results[\"predictions\"].append({\n",
        "                \"example_id\": i,\n",
        "                \"text\": ex[\"text\"],\n",
        "                \"ground_truth\": ex[\"label\"],\n",
        "                \"prediction\": prediction\n",
        "            })\n",
        "            # Save every 10 examples\n",
        "            if (i + 1) % 10 == 0:\n",
        "                with open(f\"{results_dir}/grading_boolq_{model_name}.json\", \"w\") as f:\n",
        "                    json.dump(results, f, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error on example {i}: {e}\")\n",
        "            results[\"predictions\"].append({\n",
        "                \"example_id\": i,\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "    # Save final results\n",
        "    context_suffix = \"_with_context\" if use_context else \"_no_context\"\n",
        "    with open(f\"{results_dir}/grading_boolq_{model_name}{context_suffix}.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"The question is 'does ethanol take more energy make that produces' and the answer is 'False'\",\n",
              " 'label': 'correct'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = [\n",
        "    {\"text\": x, \"label\": y}\n",
        "    for x, y in zip(X_validation, y_validation)\n",
        "]\n",
        "\n",
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = evaluate_qa_pair_judgment_llm(\n",
        "    test_data=test_data,\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    use_context=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = evaluate_qa_pair_judgment_llm(\n",
        "    test_data=test_data,\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    use_context=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26160, 9)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_files = glob.glob(\"results/*.json\")\n",
        "all_results = []\n",
        "\n",
        "for file in result_files:\n",
        "    with open(file, \"r\") as f:\n",
        "        results = json.load(f)\n",
        "        task = results.get(\"task\")\n",
        "        if not task:\n",
        "            # Heuristic: if predictions are True/False, it's answering-boolq\n",
        "            first_pred = results[\"predictions\"][0].get(\"prediction\", \"\")\n",
        "            if isinstance(first_pred, str) and (first_pred.strip().lower() in [\"true\", \"false\", \"'true'\", \"'false'\", '\"true\"', '\"false\"']):\n",
        "                task = \"answering-boolq\"\n",
        "            else:\n",
        "                task = \"grading-boolq\"\n",
        "        use_passage = results.get(\"use_passage\", results.get(\"use_context\"))\n",
        "        if use_passage is None:\n",
        "            # Try to infer from filename\n",
        "            if \"nopassage\" in file:\n",
        "                use_passage = False\n",
        "            elif \"withpassage\" in file:\n",
        "                use_passage = True\n",
        "            else:\n",
        "                # Fallback: check if 'passage' is present in any prediction\n",
        "                # For grading-boolq, the 'text' field may contain the passage\n",
        "                # Heuristic: if the word \"passage\" appears in the text, assume use_passage=True\n",
        "                first_pred = results[\"predictions\"][0]\n",
        "                if \"text\" in first_pred and \"passage\" in first_pred[\"text\"].lower():\n",
        "                    use_passage = True\n",
        "                else:\n",
        "                    use_passage = False\n",
        "        for pred in results[\"predictions\"]:\n",
        "            pred[\"model\"] = results.get(\"model\")\n",
        "            pred[\"task\"] = task\n",
        "            pred[\"use_passage\"] = use_passage\n",
        "        all_results.extend(results[\"predictions\"])\n",
        "\n",
        "df = pd.DataFrame(all_results)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>task</th>\n",
              "      <th>use_passage</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>answering-boolq</td>\n",
              "      <td>False</td>\n",
              "      <td>75.840979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answering-boolq</td>\n",
              "      <td>True</td>\n",
              "      <td>87.859327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>grading-boolq</td>\n",
              "      <td>False</td>\n",
              "      <td>70.550459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>grading-boolq</td>\n",
              "      <td>True</td>\n",
              "      <td>70.611621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              task  use_passage   accuracy\n",
              "0  answering-boolq        False  75.840979\n",
              "1  answering-boolq         True  87.859327\n",
              "2    grading-boolq        False  70.550459\n",
              "3    grading-boolq         True  70.611621"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For answering-boolq (model answers True/False)\n",
        "def normalize_answer(ans):\n",
        "    if isinstance(ans, str):\n",
        "        ans = ans.strip().lower()\n",
        "        if ans in [\"true\", \"'true'\", '\"true\"']:\n",
        "            return True\n",
        "        if ans in [\"false\", \"'false'\", '\"false\"']:\n",
        "            return False\n",
        "    if isinstance(ans, bool):\n",
        "        return ans\n",
        "    return None\n",
        "\n",
        "# For grading-boolq (model outputs {\"answer\": \"correct\"} or {\"answer\": \"incorrect\"})\n",
        "def extract_grading_label(pred):\n",
        "    if isinstance(pred, str):\n",
        "        m = re.search(r'\"answer\"\\s*:\\s*\"?(correct|incorrect)\"?', pred, re.IGNORECASE)\n",
        "        if m:\n",
        "            return m.group(1).lower()\n",
        "    return None\n",
        "\n",
        "# Prepare DataFrames for each task\n",
        "df_answering = df[df[\"task\"] == \"answering-boolq\"].copy()\n",
        "df_answering[\"prediction_norm\"] = df_answering[\"prediction\"].apply(normalize_answer)\n",
        "df_answering[\"ground_truth_norm\"] = df_answering[\"ground_truth\"].apply(\n",
        "    lambda x: x if isinstance(x, bool) else (x.lower() == \"true\")\n",
        ")\n",
        "\n",
        "df_grading = df[df[\"task\"] == \"grading-boolq\"].copy()\n",
        "df_grading[\"prediction_norm\"] = df_grading[\"prediction\"].apply(extract_grading_label)\n",
        "df_grading[\"ground_truth_norm\"] = df_grading[\"ground_truth\"].str.lower()\n",
        "\n",
        "summary = []\n",
        "for task, d in [(\"answering-boolq\", df_answering), (\"grading-boolq\", df_grading)]:\n",
        "    for context, group in d.groupby(\"use_passage\"):\n",
        "        acc = (group[\"prediction_norm\"] == group[\"ground_truth_norm\"]).mean() * 100\n",
        "        summary.append({\"task\": task, \"use_passage\": context, \"accuracy\": acc})\n",
        "summary_df = pd.DataFrame(summary)\n",
        "display(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "ax = sns.barplot(\n",
        "    data=summary_df,\n",
        "    x=\"task\",\n",
        "    y=\"accuracy\",\n",
        "    hue=\"use_passage\",\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"LLM Accuracy by Task and Context\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Task\")\n",
        "plt.legend(title=\"With Passage Context\")\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Add percentage labels on top of bars\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x() + p.get_width()/2., height + 1,\n",
        "            f'{height:.1f}%',\n",
        "            ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results reveal interesting patterns in the LLM's performance. While the model demonstrates reasonable accuracy in both tasks, its performance notably decreases when questions are framed as grading tasks. This observation aligns with the \"framing effect,\" a well-documented psychological phenomenon that appears to extend to language models as well.\n",
        "\n",
        "Regarding context usage, we observe a significant performance improvement when the passage context is provided for direct question answering. This enhancement is expected, as the additional context provides more information for the model to work with. However, this benefit does not extend to the grading task, where context appears to have minimal impact on performance. This suggests that the LLM's reasoning capabilities are more dependent on the task structure and framing rather than the availability of contextual information, highlighting the importance of task design in LLM applications.\n",
        "\n",
        "-------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thanks for reading the code, connect with me on [LinkedIn](https://www.linkedin.com/in/alvaro-francisco-gil/) or [GitHub](https://github.com/alvaro-francisco-gil) if you have any questions or comments.\n",
        "\n",
        "*Álvaro Francisco Gil*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
